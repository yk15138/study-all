2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.metrics2.lib.MutableMetricsFactory >> Method: org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42) ]
DEBUG:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.metrics2.lib.MutableMetricsFactory >> Method: org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42) ]
DEBUG:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.metrics2.lib.MutableMetricsFactory >> Method: org.apache.hadoop.metrics2.lib.MutableMetricsFactory.newForField(MutableMetricsFactory.java:42) ]
DEBUG:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.metrics2.impl.MetricsSystemImpl >> Method: org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:231) ]
DEBUG:UgiMetrics, User and group related metrics
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.authentication.util.KerberosName >> Method: org.apache.hadoop.security.authentication.util.KerberosName.<clinit>(KerberosName.java:88) ]
DEBUG:Kerberos krb5 configuration not found, setting default realm to empty
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.Groups >> Method: org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:291) ]
DEBUG: Creating new Groups object
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.util.NativeCodeLoader >> Method: org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:46) ]
DEBUG:Trying to load the custom-built native-hadoop library...
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.util.NativeCodeLoader >> Method: org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:50) ]
DEBUG:Loaded the native-hadoop library
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.JniBasedUnixGroupsMapping >> Method: org.apache.hadoop.security.JniBasedUnixGroupsMapping.<clinit>(JniBasedUnixGroupsMapping.java:50) ]
DEBUG:Using JniBasedUnixGroupsMapping for Group resolution
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback >> Method: org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.<init>(JniBasedUnixGroupsMappingWithFallback.java:45) ]
DEBUG:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.Groups >> Method: org.apache.hadoop.security.Groups.<init>(Groups.java:103) ]
DEBUG:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.UserGroupInformation >> Method: org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.login(UserGroupInformation.java:221) ]
DEBUG:hadoop login
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.UserGroupInformation >> Method: org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:156) ]
DEBUG:hadoop login commit
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.UserGroupInformation >> Method: org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:192) ]
DEBUG:Using user: "root" with name root
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.UserGroupInformation >> Method: org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:202) ]
DEBUG:User entry: "root"
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.security.UserGroupInformation >> Method: org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:825) ]
DEBUG:UGI loginUser:root (auth:SIMPLE)
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.hdfs.BlockReaderLocal >> Method: org.apache.hadoop.hdfs.DFSClient$Conf.<init>(DFSClient.java:446) ]
DEBUG:dfs.client.use.legacy.blockreader.local = false
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.hdfs.BlockReaderLocal >> Method: org.apache.hadoop.hdfs.DFSClient$Conf.<init>(DFSClient.java:449) ]
DEBUG:dfs.client.read.shortcircuit = false
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.hdfs.BlockReaderLocal >> Method: org.apache.hadoop.hdfs.DFSClient$Conf.<init>(DFSClient.java:452) ]
DEBUG:dfs.client.domain.socket.data.traffic = false
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.hdfs.BlockReaderLocal >> Method: org.apache.hadoop.hdfs.DFSClient$Conf.<init>(DFSClient.java:455) ]
DEBUG:dfs.domain.socket.path = 
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.hdfs.DFSClient >> Method: org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:637) ]
DEBUG:No KeyProvider found.
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.io.retry.RetryUtils >> Method: org.apache.hadoop.io.retry.RetryUtils.getDefaultRetryPolicy(RetryUtils.java:74) ]
DEBUG:multipleLinearRandomRetry = null
2018-12-16 15:17:01 下午 [Thread: main][ Class:org.apache.hadoop.ipc.Server >> Method: org.apache.hadoop.ipc.Server.registerProtocolEngine(Server.java:233) ]
DEBUG:rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5c33f1a9
2018-12-16 15:17:02 下午 [Thread: main][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.ClientCache.getClient(ClientCache.java:63) ]
DEBUG:getting client out of cache: org.apache.hadoop.ipc.Client@145f66e3
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.util.PerformanceAdvisory >> Method: org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.<init>(DomainSocketFactory.java:110) ]
DEBUG:Both short-circuit local reads and UNIX domain socket are disabled.
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil >> Method: org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.getSaslPropertiesResolver(DataTransferSaslUtil.java:183) ]
DEBUG:DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection.<init>(Client.java:429) ]
DEBUG:The ping interval is 60000 ms.
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:699) ]
DEBUG:Connecting to node20/192.168.174.20:9000
2018-12-16 15:17:03 下午 [Thread: IPC Client (694316372) connection to node20/192.168.174.20:9000 from root][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection.run(Client.java:963) ]
DEBUG:IPC Client (694316372) connection to node20/192.168.174.20:9000 from root: starting, having connections 1
2018-12-16 15:17:03 下午 [Thread: IPC Parameter Sending Thread #0][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection$3.run(Client.java:1026) ]
DEBUG:IPC Client (694316372) connection to node20/192.168.174.20:9000 from root sending #0
2018-12-16 15:17:03 下午 [Thread: IPC Client (694316372) connection to node20/192.168.174.20:9000 from root][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1083) ]
DEBUG:IPC Client (694316372) connection to node20/192.168.174.20:9000 from root got value #0
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.ipc.ProtobufRpcEngine >> Method: org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:253) ]
DEBUG:Call: getFileInfo took 291ms
2018-12-16 15:17:03 下午 [Thread: IPC Parameter Sending Thread #0][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection$3.run(Client.java:1026) ]
DEBUG:IPC Client (694316372) connection to node20/192.168.174.20:9000 from root sending #1
2018-12-16 15:17:03 下午 [Thread: IPC Client (694316372) connection to node20/192.168.174.20:9000 from root][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1083) ]
DEBUG:IPC Client (694316372) connection to node20/192.168.174.20:9000 from root got value #1
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.ipc.ProtobufRpcEngine >> Method: org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:253) ]
DEBUG:Call: getBlockLocations took 14ms
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.ClientCache.stopClient(ClientCache.java:97) ]
DEBUG:stopping client from cache: org.apache.hadoop.ipc.Client@145f66e3
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.ClientCache.stopClient(ClientCache.java:103) ]
DEBUG:removing client from cache: org.apache.hadoop.ipc.Client@145f66e3
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.ClientCache.stopClient(ClientCache.java:110) ]
DEBUG:stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@145f66e3
2018-12-16 15:17:03 下午 [Thread: main][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client.stop(Client.java:1236) ]
DEBUG:Stopping client
2018-12-16 15:17:03 下午 [Thread: IPC Client (694316372) connection to node20/192.168.174.20:9000 from root][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection.close(Client.java:1186) ]
DEBUG:IPC Client (694316372) connection to node20/192.168.174.20:9000 from root: closed
2018-12-16 15:17:03 下午 [Thread: IPC Client (694316372) connection to node20/192.168.174.20:9000 from root][ Class:org.apache.hadoop.ipc.Client >> Method: org.apache.hadoop.ipc.Client$Connection.run(Client.java:981) ]
DEBUG:IPC Client (694316372) connection to node20/192.168.174.20:9000 from root: stopped, remaining connections 0
